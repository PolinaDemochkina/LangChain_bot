{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:33.809568192Z",
     "start_time": "2023-11-16T11:20:33.803160789Z"
    },
    "id": "pHCfURU7MkHV",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "openai_api_key = \"\"\n",
    "gigachat_api_key = \"\"\n",
    "data_path = 'data/langchain_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "NKHFHHhSMkHW",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Устанавливаем необходимые зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T19:00:34.387784998Z",
     "start_time": "2023-11-15T18:54:39.436923296Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFtSvMmMCtCS",
    "outputId": "e4dc9483-0bac-4d40-b8aa-9ddb678ed382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.341-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: anyio<4.0 in /home/araxal/.local/lib/python3.10/site-packages (from langchain) (3.6.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-core<0.0.7,>=0.0.6 (from langchain)\n",
      "  Downloading langchain_core-0.0.6-py3-none-any.whl.metadata (750 bytes)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
      "  Downloading langsmith-0.0.67-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/araxal/.local/lib/python3.10/site-packages (from langchain) (1.22.4)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m722.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m938.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/araxal/.local/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (28 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/araxal/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/araxal/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading langchain-0.0.341-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_core-0.0.6-py3-none-any.whl (174 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.2/174.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.67-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.23-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.2/613.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydantic-core, mypy-extensions, multidict, marshmallow, jsonpatch, greenlet, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, SQLAlchemy, pydantic, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain\n",
      "Successfully installed SQLAlchemy-2.0.23 aiohttp-3.9.1 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 dataclasses-json-0.6.3 frozenlist-1.4.0 greenlet-3.0.1 jsonpatch-1.33 langchain-0.0.341 langchain-core-0.0.6 langsmith-0.0.67 marshmallow-3.20.1 multidict-6.0.4 mypy-extensions-1.0.0 pydantic-2.5.2 pydantic-core-2.14.5 typing-inspect-0.9.0 yarl-1.9.3\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/araxal/.local/lib/python3.10/site-packages (from datasets) (1.22.4)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Downloading pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pandas in /home/araxal/.local/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/araxal/.local/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Collecting huggingface-hub>=0.18.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: filelock in /home/araxal/.local/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/araxal/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/araxal/.local/lib/python3.10/site-packages (from pandas->datasets) (2022.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-14.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, pyarrow, fsspec, dill, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed datasets-2.15.0 dill-0.3.7 fsspec-2023.10.0 huggingface-hub-0.19.4 multiprocess-0.70.15 pyarrow-14.0.1 pyarrow-hotfix-0.6 xxhash-3.4.1\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m788.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m556.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/araxal/.local/lib/python3.10/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/araxal/.local/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /home/araxal/.local/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy in /home/araxal/.local/lib/python3.10/site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in /home/araxal/.local/lib/python3.10/site-packages (from sentence-transformers) (1.1.2)\n",
      "Requirement already satisfied: scipy in /home/araxal/.local/lib/python3.10/site-packages (from sentence-transformers) (1.9.2)\n",
      "Requirement already satisfied: nltk in /home/araxal/.local/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /home/araxal/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/araxal/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (65.5.0)\n",
      "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers)\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cmake in /home/araxal/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.26.3)\n",
      "Collecting lit (from triton==2.0.0->torch>=1.6.0->sentence-transformers)\n",
      "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /home/araxal/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/araxal/.local/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/araxal/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/araxal/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/araxal/.local/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "Building wheels for collected packages: sentence-transformers, lit\n",
      "  Building wheel for sentence-transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=dcf1a81be1411301c4e7b7c668d535216825fdb0b973f9870a629477b2deac3b\n",
      "  Stored in directory: /home/araxal/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=a6afbdab2c171579f17dc12154407a96b1d88dd0cfed297c495412796180b4e0\n",
      "  Stored in directory: /home/araxal/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
      "Successfully built sentence-transformers lit\n",
      "Installing collected packages: sentencepiece, lit, wheel, safetensors, tokenizers, transformers, sentence-transformers\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.12.2 requires google-auth<3,>=1.6.3, which is not installed.\n",
      "tensorboard 2.12.2 requires grpcio>=1.48.2, which is not installed.\n",
      "tensorflow 2.12.0 requires grpcio<2.0,>=1.24.3, which is not installed.\n",
      "tensorflow 2.12.0 requires wrapt<1.15,>=1.11.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed lit-17.0.6 safetensors-0.4.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.15.0 transformers-4.35.2 wheel-0.42.0\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain\n",
    "! pip install datasets\n",
    "! pip install faiss-cpu\n",
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pKE3q16MkHX",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "b2d79b29-53f4-4d83-f80b-2235383b5115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.3.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /home/araxal/.local/lib/python3.10/site-packages (from openai) (3.6.2)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: tqdm>4 in /home/araxal/.local/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/araxal/.local/lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm1\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.12.0\n",
      "    Uninstalling h11-0.12.0:\n",
      "      Successfully uninstalled h11-0.12.0\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 0.13.7\n",
      "    Uninstalling httpcore-0.13.7:\n",
      "      Successfully uninstalled httpcore-0.13.7\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.19.0\n",
      "    Uninstalling httpx-0.19.0:\n",
      "      Successfully uninstalled httpx-0.19.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spleeter 2.3.2 requires httpx[http2]<0.20.0,>=0.19.0, but you have httpx 0.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.5\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zudXkt0yMkHX",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "1c073e13-4f4d-424c-d967-b648c827249a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/araxal/.local/lib/python3.10/site-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/araxal/.local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/araxal/.pyenv/versions/3.10.11/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxfm2GRFLJhp"
   },
   "source": [
    "# Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:37.168807798Z",
     "start_time": "2023-11-16T11:20:36.311319432Z"
    },
    "id": "Y6h4tzEnkLem"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "import pandas as pd\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain, StuffDocumentsChain\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlLSSzAJLPCy"
   },
   "source": [
    "# Пишем кастомный класс получения токена авторизации для GigaChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:37.172469496Z",
     "start_time": "2023-11-16T11:20:37.170681654Z"
    },
    "id": "WRXp8TEHCcwi"
   },
   "outputs": [],
   "source": [
    "class GigaChatSecureToken:\n",
    "    access_token: str\n",
    "    expires_at: int\n",
    "    _offset: int = 60  # If token will be expired in {offset} seconds, is_expired() return true\n",
    "\n",
    "    def __init__(self, access_token: str, expires_at: int):\n",
    "        self.access_token = access_token\n",
    "        self.expires_at = expires_at\n",
    "\n",
    "    def is_expired(self):\n",
    "        return round(time.time() * 1000) > self.expires_at + self._offset * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "amuA5ofqLT1C"
   },
   "source": [
    "# Определяем кастомный класс для работы с API GigaChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:37.775199256Z",
     "start_time": "2023-11-16T11:20:37.773162530Z"
    },
    "id": "C5Cp-2A-95hY"
   },
   "outputs": [],
   "source": [
    "class GigaChatLLM(LLM):\n",
    "    api_key: str = None\n",
    "    temperature: float = 0.7\n",
    "    secure_token: GigaChatSecureToken = None\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gigachat\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "    ) -> str:\n",
    "        if not self.secure_token or self.secure_token.is_expired():\n",
    "            print(\"Obtaining new secure token\")\n",
    "            self._auth()\n",
    "            if not self.secure_token or self.secure_token.is_expired():\n",
    "                # New token was not obtained\n",
    "                print(\"ERROR: new token was not updated, cannot call LLM\")\n",
    "                return \"\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.secure_token.access_token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        req = {\n",
    "            \"model\": \"GigaChat:latest\",\n",
    "            \"messages\": [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }],\n",
    "            \"temperature\": self.temperature\n",
    "        }\n",
    "        response = requests.post(\"https://gigachat.devices.sberbank.ru/api/v1/chat/completions\", headers=headers, json=req, verify=False)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"ERROR: LLM call failed, status code: {response.status_code}\")\n",
    "            return \"\"\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    def _auth(self):\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"RqUID\": str(uuid.uuid4()),\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "        }\n",
    "\n",
    "        scope_info = {\"scope\": \"GIGACHAT_API_PERS\"}\n",
    "        response = requests.post(\"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\", data=scope_info, headers=headers, verify=False)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"ERROR: Something went wrong while obtaining secure token, status code: {response.status_code}\")\n",
    "            return\n",
    "        content = response.json()\n",
    "\n",
    "        expires_at = content[\"expires_at\"]\n",
    "        token = content[\"access_token\"]\n",
    "        if not (expires_at and token):\n",
    "            print(\"ERROR: server returns empty values for fields 'expires_at' or 'access_token'\")\n",
    "            return\n",
    "        self.secure_token = GigaChatSecureToken(token, expires_at)\n",
    "\n",
    "\n",
    "llm = GigaChatLLM(api_key=gigachat_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:39.846748298Z",
     "start_time": "2023-11-16T11:20:38.180602621Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "34-LDS8iDkFS",
    "outputId": "b6495270-24cb-4c0e-b66f-59b7a4eb9a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining new secure token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Если мы возьмём число 5 и возведём его в квадрат, то получим 25.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt=\"Пусть a = 5.  Сколько будет a в квадрате\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGl0Em1ILaq-"
   },
   "source": [
    "# Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:39.879897277Z",
     "start_time": "2023-11-16T11:20:39.847752639Z"
    },
    "id": "0is1CYMtKNyo"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUQswBdtMkHZ"
   },
   "source": [
    "# Для того чтобы эмбеддинг соджержал наибольшее количество полезной информации создадим дополнительный столбец - конкатенацию вопроса и ответа.\n",
    "\n",
    "# Также для тестирования качества поиска ближайших соседей добавим каждой строке idшник"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:39.917024306Z",
     "start_time": "2023-11-16T11:20:39.871860934Z"
    },
    "id": "5xeR_1-LMkHZ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dataframe['concatenated'] = dataframe['question'] + ' ' + dataframe['answer']\n",
    "dataframe = dataframe.assign(id=range(len(dataframe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:42.501628158Z",
     "start_time": "2023-11-16T11:20:42.493299319Z"
    },
    "id": "bUXapSuUMkHZ",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "856bd4ad-ce83-4710-e5bc-5fc6c59054d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>concatenated</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Что такое LangChain и для чего он используется?</td>\n",
       "      <td>LangChain - это фреймворк для разработки прило...</td>\n",
       "      <td>Что такое LangChain и для чего он используется...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие основные части включает в себя фреймворк...</td>\n",
       "      <td>Фреймворк LangChain включает в себя библиотеки...</td>\n",
       "      <td>Какие основные части включает в себя фреймворк...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Какие ключевые преимущества предлагают пакеты ...</td>\n",
       "      <td>Основные преимущества пакетов LangChain включа...</td>\n",
       "      <td>Какие ключевые преимущества предлагают пакеты ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Что такое LCEL в контексте LangChain?</td>\n",
       "      <td>LCEL (LangChain Expression Language) - это дек...</td>\n",
       "      <td>Что такое LCEL в контексте LangChain? LCEL (La...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Какие модули предоставляет LangChain?</td>\n",
       "      <td>LangChain предоставляет стандартные, расширяем...</td>\n",
       "      <td>Какие модули предоставляет LangChain? LangChai...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Как использовать инструменты с форматом строки...</td>\n",
       "      <td>from langchain.agents import AgentType, Tool, ...</td>\n",
       "      <td>Как использовать инструменты с форматом строки...</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Как инструменты LangChain определяют схему арг...</td>\n",
       "      <td>from typing import Any, Dict   \\n\\n    from la...</td>\n",
       "      <td>Как инструменты LangChain определяют схему арг...</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Как использовать инструменты LangChain в качес...</td>\n",
       "      <td>from langchain.chat_models import ChatOpenAI  ...</td>\n",
       "      <td>Как использовать инструменты LangChain в качес...</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Как LangChain обеспечивает асинхронную поддерж...</td>\n",
       "      <td>import asyncio   \\n    import time   \\n\\n    f...</td>\n",
       "      <td>Как LangChain обеспечивает асинхронную поддерж...</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Какие методы вызова предоставляются для классо...</td>\n",
       "      <td>chat = ChatOpenAI(temperature=0)  \\n    prompt...</td>\n",
       "      <td>Какие методы вызова предоставляются для классо...</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0      Что такое LangChain и для чего он используется?   \n",
       "1    Какие основные части включает в себя фреймворк...   \n",
       "2    Какие ключевые преимущества предлагают пакеты ...   \n",
       "3                Что такое LCEL в контексте LangChain?   \n",
       "4                Какие модули предоставляет LangChain?   \n",
       "..                                                 ...   \n",
       "377  Как использовать инструменты с форматом строки...   \n",
       "378  Как инструменты LangChain определяют схему арг...   \n",
       "379  Как использовать инструменты LangChain в качес...   \n",
       "380  Как LangChain обеспечивает асинхронную поддерж...   \n",
       "381  Какие методы вызова предоставляются для классо...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    LangChain - это фреймворк для разработки прило...   \n",
       "1    Фреймворк LangChain включает в себя библиотеки...   \n",
       "2    Основные преимущества пакетов LangChain включа...   \n",
       "3    LCEL (LangChain Expression Language) - это дек...   \n",
       "4    LangChain предоставляет стандартные, расширяем...   \n",
       "..                                                 ...   \n",
       "377  from langchain.agents import AgentType, Tool, ...   \n",
       "378  from typing import Any, Dict   \\n\\n    from la...   \n",
       "379  from langchain.chat_models import ChatOpenAI  ...   \n",
       "380  import asyncio   \\n    import time   \\n\\n    f...   \n",
       "381  chat = ChatOpenAI(temperature=0)  \\n    prompt...   \n",
       "\n",
       "                                          concatenated   id  \n",
       "0    Что такое LangChain и для чего он используется...    0  \n",
       "1    Какие основные части включает в себя фреймворк...    1  \n",
       "2    Какие ключевые преимущества предлагают пакеты ...    2  \n",
       "3    Что такое LCEL в контексте LangChain? LCEL (La...    3  \n",
       "4    Какие модули предоставляет LangChain? LangChai...    4  \n",
       "..                                                 ...  ...  \n",
       "377  Как использовать инструменты с форматом строки...  377  \n",
       "378  Как инструменты LangChain определяют схему арг...  378  \n",
       "379  Как использовать инструменты LangChain в качес...  379  \n",
       "380  Как LangChain обеспечивает асинхронную поддерж...  380  \n",
       "381  Какие методы вызова предоставляются для классо...  381  \n",
       "\n",
       "[382 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQSR3ZHWNb_e"
   },
   "source": [
    "# Трансформируем датафрейм в датафреймлоадер langchain. page_content_column в нашем случае поле concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:43.659198245Z",
     "start_time": "2023-11-16T11:20:43.636056900Z"
    },
    "id": "MHwwNoANGtqQ"
   },
   "outputs": [],
   "source": [
    "loader = DataFrameLoader(dataframe, page_content_column = 'concatenated')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:44.236013078Z",
     "start_time": "2023-11-16T11:20:44.233344780Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2xMAobYIAE8",
    "outputId": "45b23f09-e99b-4ded-c368-c53f68e459dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Что такое LangChain и для чего он используется? LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.', metadata={'question': 'Что такое LangChain и для чего он используется?', 'answer': 'LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.', 'id': 0}),\n",
       " Document(page_content='Какие основные части включает в себя фреймворк LangChain? Фреймворк LangChain включает в себя библиотеки LangChain для Python и JavaScript, коллекцию LangChain Templates для развертывания архитектур, LangServe для развертывания цепочек LangChain в виде REST API, и LangSmith - платформу для отладки и тестирования.', metadata={'question': 'Какие основные части включает в себя фреймворк LangChain?', 'answer': 'Фреймворк LangChain включает в себя библиотеки LangChain для Python и JavaScript, коллекцию LangChain Templates для развертывания архитектур, LangServe для развертывания цепочек LangChain в виде REST API, и LangSmith - платформу для отладки и тестирования.', 'id': 1})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:44.669685667Z",
     "start_time": "2023-11-16T11:20:44.660767376Z"
    },
    "id": "lvV1nHEpMkHZ",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "2fda2bb5-ede6-4da5-e613-3bf77f8e577f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts_max = dataframe['concatenated'].str.split().str.len().max()\n",
    "token_counts_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6aZS6_1Ntf_"
   },
   "source": [
    "# Определяем модель для эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:45.699923276Z",
     "start_time": "2023-11-16T11:20:45.405615284Z"
    },
    "id": "8pL4XDB6MkHZ",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "embedding_type = 'openai'\n",
    "# embedding_type = 'cointegrated/LaBSE-en-ru'\n",
    "\n",
    "if embedding_type == 'openai':\n",
    "    openai_batch_size = int(150000 / (3 * token_counts_max))\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key = openai_api_key, chunk_size = openai_batch_size)\n",
    "else:\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=embedding_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIK8xc9WPmEU"
   },
   "source": [
    "# Загружаем эмбеддинги в векторную бд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:46.514000667Z",
     "start_time": "2023-11-16T11:20:46.478243886Z"
    },
    "id": "kZ2jQQDBMY8M"
   },
   "outputs": [],
   "source": [
    "from langchain import FAISS\n",
    "from faiss import IndexHNSWFlat\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "index_name = f'{data_path}_{embedding_type}'\n",
    "\n",
    "index = IndexHNSWFlat()\n",
    "faiss = FAISS(embeddings, index, None, None)\n",
    "\n",
    "try:\n",
    "    db = FAISS.load_local(index_name, embeddings)\n",
    "except:\n",
    "    db = None\n",
    "\n",
    "if db is None:\n",
    "    if embedding_type == 'openai':\n",
    "        for batch_number in tqdm(range(0, len(data), openai_batch_size)):\n",
    "            batch = data[batch_number: batch_number + openai_batch_size]\n",
    "            batch_db = faiss.from_documents(batch, embeddings)\n",
    "            if db is None:\n",
    "                db = batch_db\n",
    "            else:\n",
    "                db.merge_from(batch_db)\n",
    "\n",
    "            sleep(20)\n",
    "    else:\n",
    "        db = faiss.from_documents(data, embeddings)\n",
    "\n",
    "    db.save_local(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:47.799821210Z",
     "start_time": "2023-11-16T11:20:46.970708555Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qDeb0pMNgJm",
    "outputId": "f6bc6e83-bc01-4594-dfaf-1a7a19d9e568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Что такое LangChain и для чего он используется? LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.', metadata={'question': 'Что такое LangChain и для чего он используется?', 'answer': 'LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.', 'id': 0}),\n",
       " Document(page_content='Какие ключевые преимущества предлагают пакеты LangChain? Основные преимущества пакетов LangChain включают в себя компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые.', metadata={'question': 'Какие ключевые преимущества предлагают пакеты LangChain?', 'answer': 'Основные преимущества пакетов LangChain включают в себя компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые.', 'id': 2}),\n",
       " Document(page_content='Какова роль LangChain в экосистеме инструментов? LangChain является частью богатой экосистемы инструментов, которые интегрируются с этим фреймворком и строятся на его основе, включая различные интеграции и руководства по лучшим практикам разработки.', metadata={'question': 'Какова роль LangChain в экосистеме инструментов?', 'answer': 'LangChain является частью богатой экосистемы инструментов, которые интегрируются с этим фреймворком и строятся на его основе, включая различные интеграции и руководства по лучшим практикам разработки.', 'id': 6}),\n",
       " Document(page_content='Какие интеграции предлагает LangChain и как они способствуют созданию приложений? LangChain предлагает обширную экосистему интеграций с различными внешними ресурсами, такими как локальные и удаленные файловые системы, API и базы данных. Эти интеграции позволяют разработчикам создавать гибкие приложения, сочетающие возможности языковых моделей (LLM) с доступом, взаимодействием и манипулированием внешними ресурсами.', metadata={'question': 'Какие интеграции предлагает LangChain и как они способствуют созданию приложений?', 'answer': 'LangChain предлагает обширную экосистему интеграций с различными внешними ресурсами, такими как локальные и удаленные файловые системы, API и базы данных. Эти интеграции позволяют разработчикам создавать гибкие приложения, сочетающие возможности языковых моделей (LLM) с доступом, взаимодействием и манипулированием внешними ресурсами.', 'id': 13}),\n",
       " Document(page_content=\"Как установить LangChain CLI и в чем его предназначение? LangChain CLI полезен для работы с шаблонами LangChain и другими проектами LangServe. Установить его можно с помощью команды 'pip install langchain-cli'.\", metadata={'question': 'Как установить LangChain CLI и в чем его предназначение?', 'answer': \"LangChain CLI полезен для работы с шаблонами LangChain и другими проектами LangServe. Установить его можно с помощью команды 'pip install langchain-cli'.\", 'id': 11})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Что такое Langchain?\"\n",
    "db.similarity_search(query, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX0NLOyPTKNe"
   },
   "source": [
    "# Определяем ретривер - верхнеуровневую обертку над similarity_search, в которую захардкожены какие-то параметры (в нашем случае 5 ближайших соседей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:48.137746909Z",
     "start_time": "2023-11-16T11:20:47.799395701Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCe3IK9mpNln",
    "outputId": "58621a01-8a2a-4682-ec0c-b1d91b2b5e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Что такое LangChain и для чего он используется? LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.', metadata={'question': 'Что такое LangChain и для чего он используется?', 'answer': 'LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.', 'id': 0}),\n",
       " Document(page_content='Какие ключевые преимущества предлагают пакеты LangChain? Основные преимущества пакетов LangChain включают в себя компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые.', metadata={'question': 'Какие ключевые преимущества предлагают пакеты LangChain?', 'answer': 'Основные преимущества пакетов LangChain включают в себя компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые.', 'id': 2}),\n",
       " Document(page_content='Какова роль LangChain в экосистеме инструментов? LangChain является частью богатой экосистемы инструментов, которые интегрируются с этим фреймворком и строятся на его основе, включая различные интеграции и руководства по лучшим практикам разработки.', metadata={'question': 'Какова роль LangChain в экосистеме инструментов?', 'answer': 'LangChain является частью богатой экосистемы инструментов, которые интегрируются с этим фреймворком и строятся на его основе, включая различные интеграции и руководства по лучшим практикам разработки.', 'id': 6}),\n",
       " Document(page_content='Какие интеграции предлагает LangChain и как они способствуют созданию приложений? LangChain предлагает обширную экосистему интеграций с различными внешними ресурсами, такими как локальные и удаленные файловые системы, API и базы данных. Эти интеграции позволяют разработчикам создавать гибкие приложения, сочетающие возможности языковых моделей (LLM) с доступом, взаимодействием и манипулированием внешними ресурсами.', metadata={'question': 'Какие интеграции предлагает LangChain и как они способствуют созданию приложений?', 'answer': 'LangChain предлагает обширную экосистему интеграций с различными внешними ресурсами, такими как локальные и удаленные файловые системы, API и базы данных. Эти интеграции позволяют разработчикам создавать гибкие приложения, сочетающие возможности языковых моделей (LLM) с доступом, взаимодействием и манипулированием внешними ресурсами.', 'id': 13}),\n",
       " Document(page_content=\"Как установить LangChain CLI и в чем его предназначение? LangChain CLI полезен для работы с шаблонами LangChain и другими проектами LangServe. Установить его можно с помощью команды 'pip install langchain-cli'.\", metadata={'question': 'Как установить LangChain CLI и в чем его предназначение?', 'answer': \"LangChain CLI полезен для работы с шаблонами LangChain и другими проектами LangServe. Установить его можно с помощью команды 'pip install langchain-cli'.\", 'id': 11})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever(search_kwargs = {\"k\": 5, \"score_threshold\": 0.3})\n",
    "retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjRyQLeXTejV"
   },
   "source": [
    "# Определяем шаблонизатор промпта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:48.321467305Z",
     "start_time": "2023-11-16T11:20:48.315738504Z"
    },
    "id": "lkz7OjWnMkHa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "Ответь на вопрос: {query}\n",
    "\n",
    "При ответе учитывай следующие имеющиеся данные:\n",
    "\"\"\"\n",
    "\n",
    "context_example_template = \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"Если вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "T_1l-VJdMkHa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Определяем пайплайн промпт template -> языковая модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnxB_hm7U2hh"
   },
   "source": [
    "# Объединяем все в одну функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:49.364862038Z",
     "start_time": "2023-11-16T11:20:49.362454296Z"
    },
    "id": "I-WX322sFlTV"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def escape_f_string(text):\n",
    "  return text.replace('{', '{{').replace('}', '}}')\n",
    "\n",
    "def escape_examples(examples):\n",
    "    return [{k: escape_f_string(v) for k, v in example.items()} for example in examples]\n",
    "\n",
    "\n",
    "def get_answer(question: str) -> Tuple[str, str]:\n",
    "  res = retriever.get_relevant_documents(question)\n",
    "  examples = [{\"context\": doc.page_content } for doc in res ]\n",
    "\n",
    "  context_example_template_prompt = PromptTemplate(\n",
    "      input_variables=[\"context\"],\n",
    "      template=context_example_template\n",
    "  )\n",
    "\n",
    "  example_selector = LengthBasedExampleSelector(\n",
    "    examples=escape_examples(examples),\n",
    "    example_prompt=context_example_template_prompt,\n",
    "    max_length=900\n",
    "  )\n",
    "\n",
    "  few_shot_prompt_template_prompt = FewShotPromptTemplate(\n",
    "    example_selector = example_selector,\n",
    "    example_prompt=context_example_template_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\"\n",
    "  )\n",
    "\n",
    "  chain = few_shot_prompt_template_prompt | llm\n",
    "\n",
    "  answer = chain.invoke({ \"query\": question })\n",
    "\n",
    "\n",
    "  prompt = few_shot_prompt_template_prompt.format(query = question)\n",
    "  return answer, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:51.526740935Z",
     "start_time": "2023-11-16T11:20:49.831221246Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGjzpsV7FpoB",
    "outputId": "96cb5a6d-62fd-4888-cf22-78f0992db2a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ответь на вопрос: Что такое Langchain?\n",
      "\n",
      "При ответе учитывай следующие имеющиеся данные:\n",
      "\n",
      "\n",
      "Что такое LangChain и для чего он используется? LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.\n",
      "\n",
      "\n",
      "Какие ключевые преимущества предлагают пакеты LangChain? Основные преимущества пакетов LangChain включают в себя компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые.\n",
      "\n",
      "\n",
      "Какова роль LangChain в экосистеме инструментов? LangChain является частью богатой экосистемы инструментов, которые интегрируются с этим фреймворком и строятся на его основе, включая различные интеграции и руководства по лучшим практикам разработки.\n",
      "\n",
      "\n",
      "Какие интеграции предлагает LangChain и как они способствуют созданию приложений? LangChain предлагает обширную экосистему интеграций с различными внешними ресурсами, такими как локальные и удаленные файловые системы, API и базы данных. Эти интеграции позволяют разработчикам создавать гибкие приложения, сочетающие возможности языковых моделей (LLM) с доступом, взаимодействием и манипулированием внешними ресурсами.\n",
      "\n",
      "\n",
      "Какие основные части включает в себя фреймворк LangChain? Фреймворк LangChain включает в себя библиотеки LangChain для Python и JavaScript, коллекцию LangChain Templates для развертывания архитектур, LangServe для развертывания цепочек LangChain в виде REST API, и LangSmith - платформу для отладки и тестирования.\n",
      "\n",
      "Если вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.\n",
      "LangChain — это фреймворк для разработки приложений, основанных на языковых моделях. Он предоставляет инструменты и компоненты для работы с языковыми моделями и создания приложений, которые могут анализировать и использовать контекст.\n",
      "\n",
      "Основные преимущества пакетов LangChain включают в себя простоту использования и настройку цепочек, а также возможность интеграции с другими инструментами и ресурсами. Это позволяет разработчикам создавать гибкие и мощные приложения, объединяющие возможности языковых моделей с другими возможностями.\n",
      "\n",
      "Фреймворк LangChain имеет обширную экосистему интеграций, которая позволяет разработчикам легко взаимодействовать с различными внешними ресурсами, такими как файловые системы, API и базы данных. Это делает возможным создание приложений, которые могут использовать эти ресурсы для обработки информации и выполнения задач.\n",
      "\n",
      "Фреймворк LangChain включает в себя несколько компонентов, таких как библиотеки для Python и JavaScript, коллекция шаблонов для развертывания архитектур, платформа для развертывания цепочек LangChain в виде REST API и платформа для отладки и тестирования. Все эти компоненты помогают разработчикам создавать и поддерживать приложения, работающие на основе языковых моделей.\n"
     ]
    }
   ],
   "source": [
    "answer, prompt = get_answer(query)\n",
    "print(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTUzn6J2WAtP"
   },
   "source": [
    "# Сравним аугментированную модель с неаугментированной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:20:51.570517836Z",
     "start_time": "2023-11-16T11:20:51.527743843Z"
    },
    "id": "-r4neAY5VHBW"
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Как подключить векторную бд в Langchain?\",\n",
    "    \"Что такое ретривер в контексте Langchain?\",\n",
    "    \"Как объединить несколько шагов в цепочку в LangChain?\",\n",
    "    \"Как в Langchain работать с OpenAiEmbeddings?\",\n",
    "    \"Как использовать CSVLoader в Langchain?\",\n",
    "    \"Как мне в CSVLoader в Langchain указать свой путь до файла если мой файл лежит в /home/user/data.csv?\",\n",
    "    \"Почему трава зеленая?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:23:12.713043436Z",
     "start_time": "2023-11-16T11:21:13.886728579Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYp59wC4VHrA",
    "outputId": "a8260452-5e20-4ef1-d7eb-7ee005fe25e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████████████████████████████▏                                                                                                                                                                                                                                                | 1/7 [00:35<03:30, 35.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining new secure token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [03:28<00:00, 29.73s/it]\n"
     ]
    }
   ],
   "source": [
    "compare_df = pd.DataFrame({\"gigachat\": [], \"gigachat + augmentation\": [], \"prompt\": []})\n",
    "i = 0\n",
    "for question in tqdm(questions):\n",
    "    llm_answer = llm(question)\n",
    "    llm_augmented_answer, llm_augmented_prompt = get_answer(question)\n",
    "\n",
    "    concat_df = pd.DataFrame.from_dict({\"gigachat\": [llm_answer], \"gigachat + augmentation\": [llm_augmented_answer], \"prompt\": [llm_augmented_prompt]})\n",
    "\n",
    "    compare_df = pd.concat([compare_df, concat_df], ignore_index = True)\n",
    "    if embedding_type == 'openai' and i < len(questions) - 1:\n",
    "        sleep(20)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:23:12.713171981Z",
     "start_time": "2023-11-16T11:23:12.710399206Z"
    },
    "id": "z0M8hRF9MkHa",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:23:12.789409105Z",
     "start_time": "2023-11-16T11:23:12.710590760Z"
    },
    "id": "Ipy2sQNGMkHa",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "49abeb5e-60f3-4f50-e6ce-9c77c26de2f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gigachat</th>\n",
       "      <th>gigachat + augmentation</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Для подключения векторной базы данных (VDB) в Langchain необходимо выполнить следующие шаги:\\n\\n1. Установить и настроить VDB на сервере базы данных.\\n2. Создать таблицу в VDB, содержащую необходимые данные для работы приложения.\\n3. Настроить соединение между приложением и VDB. Для этого необходимо указать параметры соединения, такие как хост, порт, имя пользователя и пароль.\\n4. Настроить параметры доступа к данным в VDB. Это может включать в себя установку прав доступа к таблицам и полям, а также настройку шифрования данных.\\n5. Настроить параметры безопасности соединения. Это может включать в себя установку SSL-сертификата и настройку параметров авторизации и аутентификации.\\n6. Проверить работоспособность соединения и убедиться, что приложение успешно работает с данными из VDB.\\n\\nДля более подробной информации о настройке соединения с VDB рекомендуется обратиться к документации конкретной системы управления базами данных, используемой в VDB.</td>\n",
       "      <td>Для подключения векторной базы данных в LangChain необходимо использовать модуль 'Data Connection'. Этот модуль предоставляет функциональность для загрузки документов, их преобразования, создания векторных представлений и организации эффективного поиска и извлечения информации.\\n\\nДля интеграции с 'Data Connection' в LangChain необходимо выполнить следующие шаги:\\n\\n1. Установить модуль 'Data Connection' в LangChain. Для этого можно воспользоваться командой 'pip install -e .' из исходного кода.\\n\\n2. Создать объект 'DataConnection' и настроить его параметры, такие как источник данных, формат файла и т.д.\\n\\n3. Подключить векторную базу данных к объекту 'DataConnection'. Для этого необходимо указать путь к базе данных и настроить параметры соединения, такие как имя пользователя, пароль и т.д.\\n\\n4. Использовать полученный объект 'DataConnection' для загрузки данных, создания векторных представлений и организации поиска и извлечения информации.\\n\\nИнтеграция с 'Data Connection' в LangChain позволяет расширить возможности LLM, интегрируя пользовательские данные и контекст в процесс генерации ответов. Это улучшает релевантность и точность ответов, позволяя моделям языка адаптироваться к конкретным потребностям пользователя и обеспечивая более глубокое понимание контекста запросов.</td>\n",
       "      <td>\\nОтветь на вопрос: Как подключить векторную бд в Langchain?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nЧто такое модуль 'Data Connection' в LangChain? Модуль 'Data Connection' в LangChain предоставляет функциональность для подключения к различным источникам данных и их использования в контексте LLM (Large Language Models). Это включает в себя инструменты для загрузки документов, их преобразования, создания векторных представлений и организации эффективного поиска и извлечения информации.\\n\\n\\nКакие преимущества предоставляет интеграция с 'Data Connection' в LangChain? Интеграция с 'Data Connection' в LangChain позволяет расширить возможности LLM, интегрируя пользовательские данные и контекст в процесс генерации ответов. Это улучшает релевантность и точность ответов, позволяя моделям языка адаптироваться к конкретным потребностям пользователя и обеспечивая более глубокое понимание контекста запросов.\\n\\n\\nКакие интеграции предлагает LangChain и как они способствуют созданию приложений? LangChain предлагает обширную экосистему интеграций с различными внешними ресурсами, такими как локальные и удаленные файловые системы, API и базы данных. Эти интеграции позволяют разработчикам создавать гибкие приложения, сочетающие возможности языковых моделей (LLM) с доступом, взаимодействием и манипулированием внешними ресурсами.\\n\\n\\nКакова цель объединения агентов и векторных хранилищ в LangChain? Цель объединения агентов и векторных хранилищ в LangChain - создать агента, который может взаимодействовать с данными, индексированными в векторном хранилище, и обеспечивать агентное взаимодействие для поиска и извлечения данных&amp;#8203;``【oaicite:2】``&amp;#8203;.\\n\\n\\nКак установить LangChain из исходного кода? Для установки LangChain из исходного кода необходимо клонировать репозиторий и убедиться, что директория соответствует 'PATH/TO/REPO/langchain/libs/langchain', затем выполнить команду 'pip install -e .'.\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В контексте цепочки блоков (блокчейн), термин «ретривер» относится к процессу восстановления данных из блокчейна. Это может включать восстановление данных, которые были удалены или повреждены, а также восстановление данных, которые были потеряны из-за ошибок или сбоев в системе. Ретриверы могут использовать различные методы и технологии для восстановления данных, включая использование алгоритмов криптографии, анализ журналов и другие методы.</td>\n",
       "      <td>В контексте LangChain термин \"retriever\" обозначает интерфейс, который возвращает документы, полученные в ответ на неструктурированный запрос. Это более общее понятие, чем хранилище векторов. Ретриверы могут использовать различные методы для извлечения документов, включая поиск по схожести и MMR. Они также могут быть легоковесной оберткой вокруг класса векторного хранилища.\\n\\nВ частности, Vector Store-Backed Retriever в LangChain является ретривером, который использует векторное хранилище для извлечения документов. Он использует методы поиска, реализованные векторным хранилищем, для запроса текстов в векторном хранилище.\\n\\nТакже в документах упоминается Self-querying Retriever, однако подробной информации или примеров кода, касающихся этого компонента, не предоставлено.</td>\n",
       "      <td>\\nОтветь на вопрос: Что такое ретривер в контексте Langchain?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nЧто такое 'retriever' в контексте LangChain? Retriever - это интерфейс, который возвращает документы, полученные в ответ на неструктурированный запрос. Это более общее понятие, чем хранилище векторов. Retriever не обязательно должен иметь возможность хранить документы, только возвращать (или извлекать) их. Хранилища векторов могут использоваться в качестве основы для retriever, но существуют и другие типы retriever'ов&amp;#8203;``【oaicite:4】``&amp;#8203;.\\n\\n\\nЧто такое Vector Store-Backed Retriever в LangChain? Vector Store-Backed Retriever в LangChain - это ретривер, который использует векторное хранилище для извлечения документов. Это легковесная обертка вокруг класса векторного хранилища, которая позволяет ему соответствовать интерфейсу ретривера. Он использует методы поиска, реализованные векторным хранилищем, такие как поиск по схожести и MMR, для запроса текстов в векторном хранилище&amp;#8203;``【oaicite:4】``&amp;#8203;.\\n\\n\\nЧто такое LangChain и для чего он используется? LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.\\n\\n\\nКакие методы поддерживаются интерфейсом 'retriever' в LangChain? Retriever'ы реализуют интерфейс Runnable, базовый строительный блок языка выражений LangChain (LCEL). Это означает, что они поддерживают вызовы `invoke`, `ainvoke`, `stream`, `astream`, `batch`, `abatch`, `astream_log`&amp;#8203;``【oaicite:3】``&amp;#8203;.\\n\\n\\nЧто такое Self-querying Retriever в LangChain? Self-querying Retriever - это функция или компонент в LangChain, о котором упоминается в документации. Однако на данной странице отсутствует подробная информация или примеры кода, касающиеся этого компонента&amp;#8203;``【oaicite:1】``&amp;#8203;.\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В LangChain можно объединять несколько шагов в цепочку, используя оператор `;` (запятая). Например, чтобы объединить два шага `step1` и `step2`, можно написать следующий код:\\n\\n&lt;code&gt;\\nstep1;\\nstep2;\\n&lt;/code&gt;\\n\\nТакже можно использовать оператор `;` для объединения нескольких шагов в одну строку кода. Например:\\n\\n&lt;code&gt;\\nstep1; step2; step3;\\n&lt;/code&gt;\\n\\nОбратите внимание, что оператор `;` не является обязательным элементом при объединении шагов в цепочку. Если шаги не объединены оператором `;`, они будут выполнены последовательно.</td>\n",
       "      <td>Для объединения нескольких шагов в цепочку в LangChain можно использовать пакеты 'ChatOpenAI' и 'ChatPromptTemplate'. Сначала необходимо импортировать эти пакеты, затем создать экземпляр модели и шаблона приглашения. Далее можно объединить их в цепочку, используя метод `combine_steps()`. При этом можно указать параметры, такие как `return_intermediate_steps=True`, чтобы получить доступ к промежуточным шагам агента.\\n\\nПакеты LangChain предлагают ключевые преимущества, такие как компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые. Они также предоставляют возможность выбора примеров по длине, что полезно при работе с длинными входными данными.</td>\n",
       "      <td>\\nОтветь на вопрос: Как объединить несколько шагов в цепочку в LangChain?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nКаковы преимущества использования промежуточных шагов в LangChain? Использование промежуточных шагов в LangChain позволяет лучше понять, как агент приходит к окончательному ответу. Это обеспечивает дополнительную прозрачность и позволяет пользователям или разработчикам увидеть, какие инструменты использовались и какие наблюдения были сделаны на каждом шаге процесса&amp;#8203;``【oaicite:0】``&amp;#8203;.\\n\\n\\nКакие шаги необходимо выполнить для создания и использования простой цепочки 'PromptTemplate + ChatModel' в LangChain? Для создания и использования цепочки 'PromptTemplate + ChatModel' в LangChain, необходимо импортировать 'ChatOpenAI' и 'ChatPromptTemplate', создать экземпляр модели и шаблона приглашения, а затем объединить их в цепочку.\\n\\n\\nКак можно получить доступ к промежуточным шагам агента в LangChain? В LangChain можно получить доступ к промежуточным шагам агента, используя параметр `return_intermediate_steps=True` при инициализации агента. Это позволяет отслеживать каждый шаг в цепочке действий агента, включая использование инструментов и наблюдения за результатами&amp;#8203;``【oaicite:2】``&amp;#8203;.\\n\\n\\nКакие ключевые преимущества предлагают пакеты LangChain? Основные преимущества пакетов LangChain включают в себя компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые.\\n\\n\\nВ каких сценариях полезно использовать выбор примеров по длине в LangChain? Выбор примеров по длине в LangChain полезен, когда нужно учитывать ограничения по длине запроса, особенно для моделей языка с ограниченным размером контекстного окна. Это помогает убедиться, что включенные примеры не превышают максимально допустимую длину, что особенно важно при работе с длинными входными данными.\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Для работы с OpenAiEmbeddings в Langchain необходимо выполнить следующие шаги:\\n\\n1. Установить пакет `langchain` и `openai-embeddings`.\\n\\n2. Создать экземпляр модели `OpenAiEmbeddings`.\\n\\n3. Загрузить предварительно обученную модель из файла.\\n\\n4. Выполнить запрос к модели для получения вектора представления текста.\\n\\nПример кода для работы с OpenAiEmbeddings в Langchain:\\n\\n&lt;code&gt;{python}from langchain import LanguageModel\\n\\n# Создаем экземпляр модели OpenAiEmbeddings\\nmodel = LanguageModel('path/to/model.json')\\n\\n# Загружаем предварительно обученную модель из файла\\nmodel.load_pretrained('path/to/file.h5')\\n\\n# Получаем вектор представления текста\\nvector = model.encode('Hello, world!', max_length=100)\\n&lt;/code&gt;\\n\\nВ данном примере мы создаем экземпляр модели `OpenAiEmbeddings`, загружаем предварительно обученную модель из файла и получаем вектор представления текста методом `encode()`. В качестве аргументов метода передаются текст и максимальная длина входного текста.</td>\n",
       "      <td>Для работы с OpenAIEmbeddings в LangChain необходимо выполнить следующие шаги:\\n\\n1. Импортировать необходимые модули из пакетов langchain.embeddings, langchain.indexes и langchain.schema.\\n\\n2. Создать экземпляр модели OpenAIEmbeddings и передать ей ключ API OpenAI.\\n\\n3. Создать экземпляр класса ElasticsearchStore и передать ему URL Elasticsearch, имя индекса и модель векторизации.\\n\\n4. Использовать метод embed_documents для векторизации списка документов или метод embed_query для векторизации заданного запроса.\\n\\n5. Использовать полученные векторные представления для построения индекса в Elasticsearch или для дальнейшей обработки данных в LangChain.\\n\\nПример использования OpenAIEmbeddings для встраивания списка текстов в LangChain:\\n\\n&lt;code&gt;{python}from langchain.embeddings import OpenAIEmbeddings\\nfrom langchain.indexes import ElasticsearchStore\\nfrom langchain.schema import Document\\n\\n# Создание экземпляра модели OpenAIEmbeddings\\nembeddings_model = OpenAIEmbeddings(openai_api_key=\"your-api-key\")\\n\\n# Векторизация списка документов\\nembeddings = embeddings_model.embed_documents([\\n    \"Hi there!\",\\n    \"Oh, hello!\",\\n    \"What's your name?\",\\n    \"My friends call me World\",\\n    \"Hello World!\"\\n])\\n\\n# Создание экземпляра класса ElasticsearchStore\\nvectorstore = ElasticsearchStore(es_url=\"http://localhost:9200\", index_name=\"test_index\", embedding=embeddings_model)\\n\\n# Создание экземпляра класса Document\\ndoc = Document(\"Document\", fields={\"text\": \"Hello World!\"})\\n\\n# Индексация документа в Elasticsearch\\nvectorstore.add_document(doc)\\n\\n# Получение векторного представления документа\\nvector = vectorstore.get_vector(\"test_index\", \"Document\")\\n\\n# Вывод векторного представления документа\\nprint(vector)\\n&lt;/code&gt;</td>\n",
       "      <td>\\nОтветь на вопрос: Как в Langchain работать с OpenAiEmbeddings?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nКак использовать OpenAIEmbeddings для встраивания документов в LangChain? from langchain.embeddings import OpenAIEmbeddings\\n\\nembeddings_model = OpenAIEmbeddings()\\nembeddings = embeddings_model.embed_documents([\"Hi there!\", \"Oh, hello!\", \"What's your name?\"])\\n# 'embeddings' содержит список векторных представлений для каждого текста\\n\\n\\n\\nКак использовать OpenAIEmbeddings для встраивания одиночного запроса в LangChain? from langchain.embeddings import OpenAIEmbeddings\\n\\nembeddings_model = OpenAIEmbeddings()\\n\\nembedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\\n# 'embedded_query' содержит векторное представление для заданного запроса\\n\\n\\n\\nКак начать работу с индексированием в LangChain? from langchain.embeddings import OpenAIEmbeddings   \\n    from langchain.indexes import SQLRecordManager, index   \\n    from langchain.schema import Document   \\n    from langchain.vectorstores import ElasticsearchStore   \\n\\n    collection_name = \"test_index\"  \\n    embedding = OpenAIEmbeddings()  \\n    vectorstore = ElasticsearchStore(es_url=\"http://localhost:9200\", index_name=\"test_index\", embedding=embedding)\\n\\n\\nКак использовать OpenAIEmbeddings для встраивания списка текстов в LangChain? from langchain.embeddings import OpenAIEmbeddings\\n\\nembeddings_model = OpenAIEmbeddings(openai_api_key=\"your-api-key\")\\n\\nembeddings = embeddings_model.embed_documents([\\n    \"Hi there!\",\\n    \"Oh, hello!\",\\n    \"What's your name?\",\\n    \"My friends call me World\",\\n    \"Hello World!\"\\n])\\n# 'embeddings' содержит список векторных представлений каждого текста\\n\\n\\n\\nКак работают инструменты OpenAI в LangChain? Инструменты OpenAI в LangChain позволяют взаимодействовать с OpenAI Assistants с использованием инструментов OpenAI или пользовательских инструментов. При использовании исключительно инструментов OpenAI можно непосредственно вызывать ассистента и получать окончательные ответы. При использовании пользовательских инструментов можно запускать цикл выполнения ассистента и инструментов с помощью встроенного AgentExecutor или легко написать свой собственный исполнитель&amp;#8203;``【oaicite:1】``&amp;#8203;.\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSVLoader - это класс, который используется для загрузки данных из файлов CSV (Comma-Separated Values) в язык программирования Python. Для использования CSVLoader в Langchain необходимо выполнить следующие шаги:\\n\\n1. Импортировать модуль csv в вашем коде:\\n\\n&lt;code&gt;{python}import csv\\n&lt;/code&gt;\\n\\n2. Создать объект CSVLoader и передать ему имя файла, из которого нужно загрузить данные:\\n\\n&lt;code&gt;{python}csv_loader = csv.CSVLoader()\\ndata = csv_loader.load_from_file('path/to/file.csv')\\n&lt;/code&gt;\\n\\n3. После загрузки данных можно использовать их в своем коде. Например, если у вас есть список с именами и возрастами людей, вы можете вывести их на экран:\\n\\n&lt;code&gt;{python}for name, age in data:\\n    print(name, 'is', age)\\n&lt;/code&gt;\\n\\nОбратите внимание, что CSVLoader может иметь различные параметры, такие как разделитель знаков, заголовки столбцов и т.д. Подробную информацию о параметрах можно найти в документации модуля csv.</td>\n",
       "      <td>CSVLoader в LangChain используется для эффективной загрузки и обработки данных из CSV-файлов. Он позволяет преобразовать данные в документы, которые могут быть использованы в LLM. Преимущества использования CSVLoader включают удобство интеграции и анализа табличных данных, которые широко применяются в различных бизнес- и исследовательских приложениях.\\n\\nДля загрузки данных из CSV-файла в LangChain необходимо использовать класс CSVLoader. Пример использования CSVLoader для загрузки данных из файла \"mlb_teams_2012.csv\" выглядит следующим образом:\\n\\n&lt;code&gt;{python}from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')\\ndata = loader.load()\\n# 'data' содержит список документов, загруженных из указанного CSV-файла\\n&lt;/code&gt;\\n\\nJSONLoader в LangChain предоставляет мощное средство для загрузки и обработки данных из JSON-файлов. Он поддерживает сложные структуры данных и позволяет настраивать схему извлечения. Для использования JSONLoader необходимо выбрать соответствующий загрузчик в зависимости от формата и источника данных, которые необходимо обработать.\\n\\nВ целом, в LangChain доступны различные типы Document Loaders, включая загрузчики для текстовых файлов, веб-страниц, CSV-файлов, PDF-документов, HTML-контента и многих других форматов. Выбор конкретного загрузчика зависит от требований проекта и типа данных, которые необходимо обработать.</td>\n",
       "      <td>\\nОтветь на вопрос: Как использовать CSVLoader в Langchain?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nКакие преимущества предоставляет использование CSVLoader в LangChain? CSVLoader в LangChain позволяет эффективно загружать и обрабатывать данные из CSV-файлов, преобразуя их в документы для дальнейшего использования в LLM. Это облегчает интеграцию и анализ табличных данных, которые часто используются в различных бизнес- и исследовательских приложениях.\\n\\n\\nКак использовать CSVLoader для загрузки данных из CSV-файла в LangChain? from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')\\ndata = loader.load()\\n# 'data' содержит список документов, загруженных из указанного CSV-файла\\n\\n\\nКаковы преимущества использования JSONLoader в LangChain для обработки JSON-данных? JSONLoader в LangChain обеспечивает гибкое и мощное средство для загрузки и обработки данных из JSON-файлов, включая поддержку сложных структур данных и возможность настройки схемы извлечения. Это позволяет эффективно интегрировать и использовать JSON-данные в различных приложениях на основе LangChain.\\n\\n\\nКакие типы Document Loaders доступны в LangChain? В LangChain доступны различные типы Document Loaders, включая загрузчики для текстовых файлов, веб-страниц, CSV-файлов, PDF-документов, HTML-контента и многих других форматов. Это позволяет пользователям выбирать подходящий загрузчик в зависимости от формата и источника данных, которые им необходимо обработать.\\n\\n\\nКак настроить CSVLoader для использования кастомных параметров парсинга CSV в LangChain? from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv', csv_args={\\n    'delimiter': ',',\\n    'quotechar': '\"',\\n    'fieldnames': ['MLB Team', 'Payroll in millions', 'Wins']\\n})\\ndata = loader.load()\\n# 'data' содержит список документов с кастомными параметрами парсинга\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Для указания пути к файлу в CSVLoader в Langchain необходимо использовать параметр `file_path` при создании экземпляра класса `CSVLoader`. \\n\\nПример использования:\\n\\n&lt;code&gt;{python}from langchain import CSVLoader\\n\\n# Создаем экземпляр класса CSVLoader\\nloader = CSVLoader(file_path='/home/user/data.csv')\\n&lt;/code&gt;\\n\\nВ данном примере мы указываем путь к файлу `/home/user/data.csv`. Если файл находится в другой директории, то необходимо указать полный путь к файлу.</td>\n",
       "      <td>Для указания пути к файлу в CSVLoader в LangChain необходимо использовать аргумент `file_path` при создании экземпляра класса `CSVLoader`. В данном случае, если файл находится в директории `/home/user/data.csv`, можно создать экземпляр класса следующим образом:\\n\\n&lt;code&gt;{python}from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='/home/user/data.csv')\\ndata = loader.load()\\n&lt;/code&gt;\\n\\nВ этом примере мы указываем путь к файлу `/home/user/data.csv`. При использовании этого метода, CSVLoader автоматически загрузит данные из указанного файла и вернет их в виде списка документов.</td>\n",
       "      <td>\\nОтветь на вопрос: Как мне в CSVLoader в Langchain указать свой путь до файла если мой файл лежит в /home/user/data.csv?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nКакие преимущества предоставляет использование CSVLoader в LangChain? CSVLoader в LangChain позволяет эффективно загружать и обрабатывать данные из CSV-файлов, преобразуя их в документы для дальнейшего использования в LLM. Это облегчает интеграцию и анализ табличных данных, которые часто используются в различных бизнес- и исследовательских приложениях.\\n\\n\\nКак использовать CSVLoader для загрузки данных из CSV-файла в LangChain? from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')\\ndata = loader.load()\\n# 'data' содержит список документов, загруженных из указанного CSV-файла\\n\\n\\nКак настроить CSVLoader для использования кастомных параметров парсинга CSV в LangChain? from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv', csv_args={\\n    'delimiter': ',',\\n    'quotechar': '\"',\\n    'fieldnames': ['MLB Team', 'Payroll in millions', 'Wins']\\n})\\ndata = loader.load()\\n# 'data' содержит список документов с кастомными параметрами парсинга\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Зеленый цвет растениям придаёт хлорофилл — зеленый пигмент, который участвует в процессе фотосинтеза. Хлорофилл поглощает световую энергию и использует её для превращения углекислого газа и воды в глюкозу и кислород. Этот процесс происходит в хлоропластах растительных клеток. В результате фотосинтеза растения выделяют кислород в атмосферу и используют глюкозу для своего роста и развития.</td>\n",
       "      <td>Трава зеленая из-за наличия хлорофилла в ее клетках. Хлорофилл является основным пигментом, который поглощает световую энергию и использует ее для фотосинтеза — процесса, при котором растения преобразуют солнечную энергию в химическую энергию, необходимую для роста и развития. Зеленый цвет хлорофилла обусловлен его способностью поглощать световые волны определенной длины, что позволяет ему эффективно использовать доступную энергию. Таким образом, благодаря зеленому пигменту, трава способна получать энергию от солнца и превращать ее в питательные вещества, необходимые для ее роста и развития.</td>\n",
       "      <td>\\nОтветь на вопрос: Почему трава зеленая?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          gigachat  \\\n",
       "0                                Для подключения векторной базы данных (VDB) в Langchain необходимо выполнить следующие шаги:\\n\\n1. Установить и настроить VDB на сервере базы данных.\\n2. Создать таблицу в VDB, содержащую необходимые данные для работы приложения.\\n3. Настроить соединение между приложением и VDB. Для этого необходимо указать параметры соединения, такие как хост, порт, имя пользователя и пароль.\\n4. Настроить параметры доступа к данным в VDB. Это может включать в себя установку прав доступа к таблицам и полям, а также настройку шифрования данных.\\n5. Настроить параметры безопасности соединения. Это может включать в себя установку SSL-сертификата и настройку параметров авторизации и аутентификации.\\n6. Проверить работоспособность соединения и убедиться, что приложение успешно работает с данными из VDB.\\n\\nДля более подробной информации о настройке соединения с VDB рекомендуется обратиться к документации конкретной системы управления базами данных, используемой в VDB.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    В контексте цепочки блоков (блокчейн), термин «ретривер» относится к процессу восстановления данных из блокчейна. Это может включать восстановление данных, которые были удалены или повреждены, а также восстановление данных, которые были потеряны из-за ошибок или сбоев в системе. Ретриверы могут использовать различные методы и технологии для восстановления данных, включая использование алгоритмов криптографии, анализ журналов и другие методы.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                       В LangChain можно объединять несколько шагов в цепочку, используя оператор `;` (запятая). Например, чтобы объединить два шага `step1` и `step2`, можно написать следующий код:\\n\\n<code>\\nstep1;\\nstep2;\\n</code>\\n\\nТакже можно использовать оператор `;` для объединения нескольких шагов в одну строку кода. Например:\\n\\n<code>\\nstep1; step2; step3;\\n</code>\\n\\nОбратите внимание, что оператор `;` не является обязательным элементом при объединении шагов в цепочку. Если шаги не объединены оператором `;`, они будут выполнены последовательно.   \n",
       "3  Для работы с OpenAiEmbeddings в Langchain необходимо выполнить следующие шаги:\\n\\n1. Установить пакет `langchain` и `openai-embeddings`.\\n\\n2. Создать экземпляр модели `OpenAiEmbeddings`.\\n\\n3. Загрузить предварительно обученную модель из файла.\\n\\n4. Выполнить запрос к модели для получения вектора представления текста.\\n\\nПример кода для работы с OpenAiEmbeddings в Langchain:\\n\\n<code>{python}from langchain import LanguageModel\\n\\n# Создаем экземпляр модели OpenAiEmbeddings\\nmodel = LanguageModel('path/to/model.json')\\n\\n# Загружаем предварительно обученную модель из файла\\nmodel.load_pretrained('path/to/file.h5')\\n\\n# Получаем вектор представления текста\\nvector = model.encode('Hello, world!', max_length=100)\\n</code>\\n\\nВ данном примере мы создаем экземпляр модели `OpenAiEmbeddings`, загружаем предварительно обученную модель из файла и получаем вектор представления текста методом `encode()`. В качестве аргументов метода передаются текст и максимальная длина входного текста.   \n",
       "4                                                                 CSVLoader - это класс, который используется для загрузки данных из файлов CSV (Comma-Separated Values) в язык программирования Python. Для использования CSVLoader в Langchain необходимо выполнить следующие шаги:\\n\\n1. Импортировать модуль csv в вашем коде:\\n\\n<code>{python}import csv\\n</code>\\n\\n2. Создать объект CSVLoader и передать ему имя файла, из которого нужно загрузить данные:\\n\\n<code>{python}csv_loader = csv.CSVLoader()\\ndata = csv_loader.load_from_file('path/to/file.csv')\\n</code>\\n\\n3. После загрузки данных можно использовать их в своем коде. Например, если у вас есть список с именами и возрастами людей, вы можете вывести их на экран:\\n\\n<code>{python}for name, age in data:\\n    print(name, 'is', age)\\n</code>\\n\\nОбратите внимание, что CSVLoader может иметь различные параметры, такие как разделитель знаков, заголовки столбцов и т.д. Подробную информацию о параметрах можно найти в документации модуля csv.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Для указания пути к файлу в CSVLoader в Langchain необходимо использовать параметр `file_path` при создании экземпляра класса `CSVLoader`. \\n\\nПример использования:\\n\\n<code>{python}from langchain import CSVLoader\\n\\n# Создаем экземпляр класса CSVLoader\\nloader = CSVLoader(file_path='/home/user/data.csv')\\n</code>\\n\\nВ данном примере мы указываем путь к файлу `/home/user/data.csv`. Если файл находится в другой директории, то необходимо указать полный путь к файлу.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Зеленый цвет растениям придаёт хлорофилл — зеленый пигмент, который участвует в процессе фотосинтеза. Хлорофилл поглощает световую энергию и использует её для превращения углекислого газа и воды в глюкозу и кислород. Этот процесс происходит в хлоропластах растительных клеток. В результате фотосинтеза растения выделяют кислород в атмосферу и используют глюкозу для своего роста и развития.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 gigachat + augmentation  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Для подключения векторной базы данных в LangChain необходимо использовать модуль 'Data Connection'. Этот модуль предоставляет функциональность для загрузки документов, их преобразования, создания векторных представлений и организации эффективного поиска и извлечения информации.\\n\\nДля интеграции с 'Data Connection' в LangChain необходимо выполнить следующие шаги:\\n\\n1. Установить модуль 'Data Connection' в LangChain. Для этого можно воспользоваться командой 'pip install -e .' из исходного кода.\\n\\n2. Создать объект 'DataConnection' и настроить его параметры, такие как источник данных, формат файла и т.д.\\n\\n3. Подключить векторную базу данных к объекту 'DataConnection'. Для этого необходимо указать путь к базе данных и настроить параметры соединения, такие как имя пользователя, пароль и т.д.\\n\\n4. Использовать полученный объект 'DataConnection' для загрузки данных, создания векторных представлений и организации поиска и извлечения информации.\\n\\nИнтеграция с 'Data Connection' в LangChain позволяет расширить возможности LLM, интегрируя пользовательские данные и контекст в процесс генерации ответов. Это улучшает релевантность и точность ответов, позволяя моделям языка адаптироваться к конкретным потребностям пользователя и обеспечивая более глубокое понимание контекста запросов.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         В контексте LangChain термин \"retriever\" обозначает интерфейс, который возвращает документы, полученные в ответ на неструктурированный запрос. Это более общее понятие, чем хранилище векторов. Ретриверы могут использовать различные методы для извлечения документов, включая поиск по схожести и MMR. Они также могут быть легоковесной оберткой вокруг класса векторного хранилища.\\n\\nВ частности, Vector Store-Backed Retriever в LangChain является ретривером, который использует векторное хранилище для извлечения документов. Он использует методы поиска, реализованные векторным хранилищем, для запроса текстов в векторном хранилище.\\n\\nТакже в документах упоминается Self-querying Retriever, однако подробной информации или примеров кода, касающихся этого компонента, не предоставлено.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Для объединения нескольких шагов в цепочку в LangChain можно использовать пакеты 'ChatOpenAI' и 'ChatPromptTemplate'. Сначала необходимо импортировать эти пакеты, затем создать экземпляр модели и шаблона приглашения. Далее можно объединить их в цепочку, используя метод `combine_steps()`. При этом можно указать параметры, такие как `return_intermediate_steps=True`, чтобы получить доступ к промежуточным шагам агента.\\n\\nПакеты LangChain предлагают ключевые преимущества, такие как компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые. Они также предоставляют возможность выбора примеров по длине, что полезно при работе с длинными входными данными.   \n",
       "3  Для работы с OpenAIEmbeddings в LangChain необходимо выполнить следующие шаги:\\n\\n1. Импортировать необходимые модули из пакетов langchain.embeddings, langchain.indexes и langchain.schema.\\n\\n2. Создать экземпляр модели OpenAIEmbeddings и передать ей ключ API OpenAI.\\n\\n3. Создать экземпляр класса ElasticsearchStore и передать ему URL Elasticsearch, имя индекса и модель векторизации.\\n\\n4. Использовать метод embed_documents для векторизации списка документов или метод embed_query для векторизации заданного запроса.\\n\\n5. Использовать полученные векторные представления для построения индекса в Elasticsearch или для дальнейшей обработки данных в LangChain.\\n\\nПример использования OpenAIEmbeddings для встраивания списка текстов в LangChain:\\n\\n<code>{python}from langchain.embeddings import OpenAIEmbeddings\\nfrom langchain.indexes import ElasticsearchStore\\nfrom langchain.schema import Document\\n\\n# Создание экземпляра модели OpenAIEmbeddings\\nembeddings_model = OpenAIEmbeddings(openai_api_key=\"your-api-key\")\\n\\n# Векторизация списка документов\\nembeddings = embeddings_model.embed_documents([\\n    \"Hi there!\",\\n    \"Oh, hello!\",\\n    \"What's your name?\",\\n    \"My friends call me World\",\\n    \"Hello World!\"\\n])\\n\\n# Создание экземпляра класса ElasticsearchStore\\nvectorstore = ElasticsearchStore(es_url=\"http://localhost:9200\", index_name=\"test_index\", embedding=embeddings_model)\\n\\n# Создание экземпляра класса Document\\ndoc = Document(\"Document\", fields={\"text\": \"Hello World!\"})\\n\\n# Индексация документа в Elasticsearch\\nvectorstore.add_document(doc)\\n\\n# Получение векторного представления документа\\nvector = vectorstore.get_vector(\"test_index\", \"Document\")\\n\\n# Вывод векторного представления документа\\nprint(vector)\\n</code>   \n",
       "4                                                                                                                                                                                                                                                                                                                               CSVLoader в LangChain используется для эффективной загрузки и обработки данных из CSV-файлов. Он позволяет преобразовать данные в документы, которые могут быть использованы в LLM. Преимущества использования CSVLoader включают удобство интеграции и анализа табличных данных, которые широко применяются в различных бизнес- и исследовательских приложениях.\\n\\nДля загрузки данных из CSV-файла в LangChain необходимо использовать класс CSVLoader. Пример использования CSVLoader для загрузки данных из файла \"mlb_teams_2012.csv\" выглядит следующим образом:\\n\\n<code>{python}from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')\\ndata = loader.load()\\n# 'data' содержит список документов, загруженных из указанного CSV-файла\\n</code>\\n\\nJSONLoader в LangChain предоставляет мощное средство для загрузки и обработки данных из JSON-файлов. Он поддерживает сложные структуры данных и позволяет настраивать схему извлечения. Для использования JSONLoader необходимо выбрать соответствующий загрузчик в зависимости от формата и источника данных, которые необходимо обработать.\\n\\nВ целом, в LangChain доступны различные типы Document Loaders, включая загрузчики для текстовых файлов, веб-страниц, CSV-файлов, PDF-документов, HTML-контента и многих других форматов. Выбор конкретного загрузчика зависит от требований проекта и типа данных, которые необходимо обработать.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Для указания пути к файлу в CSVLoader в LangChain необходимо использовать аргумент `file_path` при создании экземпляра класса `CSVLoader`. В данном случае, если файл находится в директории `/home/user/data.csv`, можно создать экземпляр класса следующим образом:\\n\\n<code>{python}from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='/home/user/data.csv')\\ndata = loader.load()\\n</code>\\n\\nВ этом примере мы указываем путь к файлу `/home/user/data.csv`. При использовании этого метода, CSVLoader автоматически загрузит данные из указанного файла и вернет их в виде списка документов.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Трава зеленая из-за наличия хлорофилла в ее клетках. Хлорофилл является основным пигментом, который поглощает световую энергию и использует ее для фотосинтеза — процесса, при котором растения преобразуют солнечную энергию в химическую энергию, необходимую для роста и развития. Зеленый цвет хлорофилла обусловлен его способностью поглощать световые волны определенной длины, что позволяет ему эффективно использовать доступную энергию. Таким образом, благодаря зеленому пигменту, трава способна получать энергию от солнца и превращать ее в питательные вещества, необходимые для ее роста и развития.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           prompt  \n",
       "0                                                                                                                                                                                                                                                                                                                                                               \\nОтветь на вопрос: Как подключить векторную бд в Langchain?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nЧто такое модуль 'Data Connection' в LangChain? Модуль 'Data Connection' в LangChain предоставляет функциональность для подключения к различным источникам данных и их использования в контексте LLM (Large Language Models). Это включает в себя инструменты для загрузки документов, их преобразования, создания векторных представлений и организации эффективного поиска и извлечения информации.\\n\\n\\nКакие преимущества предоставляет интеграция с 'Data Connection' в LangChain? Интеграция с 'Data Connection' в LangChain позволяет расширить возможности LLM, интегрируя пользовательские данные и контекст в процесс генерации ответов. Это улучшает релевантность и точность ответов, позволяя моделям языка адаптироваться к конкретным потребностям пользователя и обеспечивая более глубокое понимание контекста запросов.\\n\\n\\nКакие интеграции предлагает LangChain и как они способствуют созданию приложений? LangChain предлагает обширную экосистему интеграций с различными внешними ресурсами, такими как локальные и удаленные файловые системы, API и базы данных. Эти интеграции позволяют разработчикам создавать гибкие приложения, сочетающие возможности языковых моделей (LLM) с доступом, взаимодействием и манипулированием внешними ресурсами.\\n\\n\\nКакова цель объединения агентов и векторных хранилищ в LangChain? Цель объединения агентов и векторных хранилищ в LangChain - создать агента, который может взаимодействовать с данными, индексированными в векторном хранилище, и обеспечивать агентное взаимодействие для поиска и извлечения данных&#8203;``【oaicite:2】``&#8203;.\\n\\n\\nКак установить LangChain из исходного кода? Для установки LangChain из исходного кода необходимо клонировать репозиторий и убедиться, что директория соответствует 'PATH/TO/REPO/langchain/libs/langchain', затем выполнить команду 'pip install -e .'.\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                            \\nОтветь на вопрос: Что такое ретривер в контексте Langchain?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nЧто такое 'retriever' в контексте LangChain? Retriever - это интерфейс, который возвращает документы, полученные в ответ на неструктурированный запрос. Это более общее понятие, чем хранилище векторов. Retriever не обязательно должен иметь возможность хранить документы, только возвращать (или извлекать) их. Хранилища векторов могут использоваться в качестве основы для retriever, но существуют и другие типы retriever'ов&#8203;``【oaicite:4】``&#8203;.\\n\\n\\nЧто такое Vector Store-Backed Retriever в LangChain? Vector Store-Backed Retriever в LangChain - это ретривер, который использует векторное хранилище для извлечения документов. Это легковесная обертка вокруг класса векторного хранилища, которая позволяет ему соответствовать интерфейсу ретривера. Он использует методы поиска, реализованные векторным хранилищем, такие как поиск по схожести и MMR, для запроса текстов в векторном хранилище&#8203;``【oaicite:4】``&#8203;.\\n\\n\\nЧто такое LangChain и для чего он используется? LangChain - это фреймворк для разработки приложений, работающих на основе языковых моделей. Он позволяет создавать приложения, которые осведомлены о контексте и могут осуществлять рассуждения на основе предоставленного контекста.\\n\\n\\nКакие методы поддерживаются интерфейсом 'retriever' в LangChain? Retriever'ы реализуют интерфейс Runnable, базовый строительный блок языка выражений LangChain (LCEL). Это означает, что они поддерживают вызовы `invoke`, `ainvoke`, `stream`, `astream`, `batch`, `abatch`, `astream_log`&#8203;``【oaicite:3】``&#8203;.\\n\\n\\nЧто такое Self-querying Retriever в LangChain? Self-querying Retriever - это функция или компонент в LangChain, о котором упоминается в документации. Однако на данной странице отсутствует подробная информация или примеры кода, касающиеся этого компонента&#8203;``【oaicite:1】``&#8203;.\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                          \\nОтветь на вопрос: Как объединить несколько шагов в цепочку в LangChain?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nКаковы преимущества использования промежуточных шагов в LangChain? Использование промежуточных шагов в LangChain позволяет лучше понять, как агент приходит к окончательному ответу. Это обеспечивает дополнительную прозрачность и позволяет пользователям или разработчикам увидеть, какие инструменты использовались и какие наблюдения были сделаны на каждом шаге процесса&#8203;``【oaicite:0】``&#8203;.\\n\\n\\nКакие шаги необходимо выполнить для создания и использования простой цепочки 'PromptTemplate + ChatModel' в LangChain? Для создания и использования цепочки 'PromptTemplate + ChatModel' в LangChain, необходимо импортировать 'ChatOpenAI' и 'ChatPromptTemplate', создать экземпляр модели и шаблона приглашения, а затем объединить их в цепочку.\\n\\n\\nКак можно получить доступ к промежуточным шагам агента в LangChain? В LangChain можно получить доступ к промежуточным шагам агента, используя параметр `return_intermediate_steps=True` при инициализации агента. Это позволяет отслеживать каждый шаг в цепочке действий агента, включая использование инструментов и наблюдения за результатами&#8203;``【oaicite:2】``&#8203;.\\n\\n\\nКакие ключевые преимущества предлагают пакеты LangChain? Основные преимущества пакетов LangChain включают в себя компоненты для работы с языковыми моделями и готовые цепочки, которые облегчают начало работы и позволяют настраивать существующие цепочки или создавать новые.\\n\\n\\nВ каких сценариях полезно использовать выбор примеров по длине в LangChain? Выбор примеров по длине в LangChain полезен, когда нужно учитывать ограничения по длине запроса, особенно для моделей языка с ограниченным размером контекстного окна. Это помогает убедиться, что включенные примеры не превышают максимально допустимую длину, что особенно важно при работе с длинными входными данными.\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.  \n",
       "3  \\nОтветь на вопрос: Как в Langchain работать с OpenAiEmbeddings?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nКак использовать OpenAIEmbeddings для встраивания документов в LangChain? from langchain.embeddings import OpenAIEmbeddings\\n\\nembeddings_model = OpenAIEmbeddings()\\nembeddings = embeddings_model.embed_documents([\"Hi there!\", \"Oh, hello!\", \"What's your name?\"])\\n# 'embeddings' содержит список векторных представлений для каждого текста\\n\\n\\n\\nКак использовать OpenAIEmbeddings для встраивания одиночного запроса в LangChain? from langchain.embeddings import OpenAIEmbeddings\\n\\nembeddings_model = OpenAIEmbeddings()\\n\\nembedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\\n# 'embedded_query' содержит векторное представление для заданного запроса\\n\\n\\n\\nКак начать работу с индексированием в LangChain? from langchain.embeddings import OpenAIEmbeddings   \\n    from langchain.indexes import SQLRecordManager, index   \\n    from langchain.schema import Document   \\n    from langchain.vectorstores import ElasticsearchStore   \\n\\n    collection_name = \"test_index\"  \\n    embedding = OpenAIEmbeddings()  \\n    vectorstore = ElasticsearchStore(es_url=\"http://localhost:9200\", index_name=\"test_index\", embedding=embedding)\\n\\n\\nКак использовать OpenAIEmbeddings для встраивания списка текстов в LangChain? from langchain.embeddings import OpenAIEmbeddings\\n\\nembeddings_model = OpenAIEmbeddings(openai_api_key=\"your-api-key\")\\n\\nembeddings = embeddings_model.embed_documents([\\n    \"Hi there!\",\\n    \"Oh, hello!\",\\n    \"What's your name?\",\\n    \"My friends call me World\",\\n    \"Hello World!\"\\n])\\n# 'embeddings' содержит список векторных представлений каждого текста\\n\\n\\n\\nКак работают инструменты OpenAI в LangChain? Инструменты OpenAI в LangChain позволяют взаимодействовать с OpenAI Assistants с использованием инструментов OpenAI или пользовательских инструментов. При использовании исключительно инструментов OpenAI можно непосредственно вызывать ассистента и получать окончательные ответы. При использовании пользовательских инструментов можно запускать цикл выполнения ассистента и инструментов с помощью встроенного AgentExecutor или легко написать свой собственный исполнитель&#8203;``【oaicite:1】``&#8203;.\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.  \n",
       "4                                                                                                                                                                                                                                                                                                                     \\nОтветь на вопрос: Как использовать CSVLoader в Langchain?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nКакие преимущества предоставляет использование CSVLoader в LangChain? CSVLoader в LangChain позволяет эффективно загружать и обрабатывать данные из CSV-файлов, преобразуя их в документы для дальнейшего использования в LLM. Это облегчает интеграцию и анализ табличных данных, которые часто используются в различных бизнес- и исследовательских приложениях.\\n\\n\\nКак использовать CSVLoader для загрузки данных из CSV-файла в LangChain? from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')\\ndata = loader.load()\\n# 'data' содержит список документов, загруженных из указанного CSV-файла\\n\\n\\nКаковы преимущества использования JSONLoader в LangChain для обработки JSON-данных? JSONLoader в LangChain обеспечивает гибкое и мощное средство для загрузки и обработки данных из JSON-файлов, включая поддержку сложных структур данных и возможность настройки схемы извлечения. Это позволяет эффективно интегрировать и использовать JSON-данные в различных приложениях на основе LangChain.\\n\\n\\nКакие типы Document Loaders доступны в LangChain? В LangChain доступны различные типы Document Loaders, включая загрузчики для текстовых файлов, веб-страниц, CSV-файлов, PDF-документов, HTML-контента и многих других форматов. Это позволяет пользователям выбирать подходящий загрузчик в зависимости от формата и источника данных, которые им необходимо обработать.\\n\\n\\nКак настроить CSVLoader для использования кастомных параметров парсинга CSV в LangChain? from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv', csv_args={\\n    'delimiter': ',',\\n    'quotechar': '\"',\\n    'fieldnames': ['MLB Team', 'Payroll in millions', 'Wins']\\n})\\ndata = loader.load()\\n# 'data' содержит список документов с кастомными параметрами парсинга\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.  \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \\nОтветь на вопрос: Как мне в CSVLoader в Langchain указать свой путь до файла если мой файл лежит в /home/user/data.csv?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\n\\nКакие преимущества предоставляет использование CSVLoader в LangChain? CSVLoader в LangChain позволяет эффективно загружать и обрабатывать данные из CSV-файлов, преобразуя их в документы для дальнейшего использования в LLM. Это облегчает интеграцию и анализ табличных данных, которые часто используются в различных бизнес- и исследовательских приложениях.\\n\\n\\nКак использовать CSVLoader для загрузки данных из CSV-файла в LangChain? from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')\\ndata = loader.load()\\n# 'data' содержит список документов, загруженных из указанного CSV-файла\\n\\n\\nКак настроить CSVLoader для использования кастомных параметров парсинга CSV в LangChain? from langchain.document_loaders.csv_loader import CSVLoader\\n\\nloader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv', csv_args={\\n    'delimiter': ',',\\n    'quotechar': '\"',\\n    'fieldnames': ['MLB Team', 'Payroll in millions', 'Wins']\\n})\\ndata = loader.load()\\n# 'data' содержит список документов с кастомными параметрами парсинга\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.  \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \\nОтветь на вопрос: Почему трава зеленая?\\n\\nПри ответе учитывай следующие имеющиеся данные:\\n\\nЕсли вопрос тесно связан с предоставленными данными, используй их при формировании своего ответа.  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T11:23:12.820341942Z",
     "start_time": "2023-11-16T11:23:12.750568945Z"
    },
    "id": "-GflZYeWMkHb",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "compare_df.to_html('final_work_result.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcJ6hSvFMkHb"
   },
   "source": [
    "# Посмотрим качество наших эмбеддингов - насколько они правильно находят ответ по запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_vCXeQZMkHb"
   },
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "retriever = db.as_retriever(search_kwargs = {\"k\": top_n, \"score_threshold\": 0.3})\n",
    "\n",
    "test_subset_len = 20\n",
    "doc_length = min(len(data), test_subset_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6R-mxWVMkHb"
   },
   "source": [
    "# Посмотрим accuracy когда мы задаем точно такие же вопросы, котоые есть в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ9xo8E3MkHb",
    "outputId": "656fc0f1-faa3-4e50-b167-b31c1a4a0a0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [06:53<00:00, 20.67s/it]\n"
     ]
    }
   ],
   "source": [
    "relevant_in_top_n = 0\n",
    "\n",
    "for doc in tqdm(data[:test_subset_len]):\n",
    "    question = doc.metadata['question']\n",
    "    question_id = doc.metadata['id']\n",
    "\n",
    "    relevant_documents = retriever.get_relevant_documents(question)\n",
    "    relevant_document_ids = map(lambda x: x.metadata['id'], relevant_documents)\n",
    "    if question_id in relevant_document_ids:\n",
    "        relevant_in_top_n += 1\n",
    "\n",
    "    sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TmX1eYTMkHb",
    "outputId": "e1135cba-97ce-41f7-e0ed-fb9ee81a7a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тех же вопросах 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Точность на тех же вопросах {relevant_in_top_n / doc_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ai7jtZGsMkHb"
   },
   "source": [
    "# Попроисим gigachat переформулировать наши вопросы и проверим точность на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PouktMQ1MkHb",
    "outputId": "74dc6e81-1144-4589-8c7d-84945d69bce2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [07:22<00:00, 22.11s/it]\n"
     ]
    }
   ],
   "source": [
    "relevant_in_top_n = 0\n",
    "question_dict = {\n",
    "    'questions': [],\n",
    "    'rephrased_questions': []\n",
    "}\n",
    "\n",
    "\n",
    "for doc in tqdm(data[:test_subset_len]):\n",
    "    question = doc.metadata['question']\n",
    "    question_id = doc.metadata['id']\n",
    "\n",
    "    rephrased_question = llm(f'Переформулируй этот вопрос: {question}')\n",
    "\n",
    "    question_dict['questions'].append(question)\n",
    "    question_dict['rephrased_questions'].append(rephrased_question)\n",
    "\n",
    "    relevant_documents = retriever.get_relevant_documents(rephrased_question)\n",
    "    relevant_document_ids = map(lambda x: x.metadata['id'], relevant_documents)\n",
    "    if question_id in relevant_document_ids:\n",
    "        relevant_in_top_n += 1\n",
    "\n",
    "    sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCFzoEr-MkHb",
    "outputId": "ac0f4da4-285e-474a-f816-4c4dee156226"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>rephrased_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Что такое LangChain и для чего он используется?</td>\n",
       "      <td>Для чего предназначен LangChain и что это за технология?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие основные части включает в себя фреймворк LangChain?</td>\n",
       "      <td>Какие компоненты входят в состав фреймворка LangChain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Какие ключевые преимущества предлагают пакеты LangChain?</td>\n",
       "      <td>Какие основные преимущества предоставляют пакеты LangChain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Что такое LCEL в контексте LangChain?</td>\n",
       "      <td>В контексте LangChain, что означает LCEL?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Какие модули предоставляет LangChain?</td>\n",
       "      <td>Какие функциональные возможности предлагает LangChain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Какие примеры использования LangChain приведены в документации?</td>\n",
       "      <td>В документации приведены какие примеры использования LangChain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Какова роль LangChain в экосистеме инструментов?</td>\n",
       "      <td>Какую роль играет LangChain в экосистеме инструментов?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Как установить LangChain с использованием Pip и Conda?</td>\n",
       "      <td>Как можно установить пакет LangChain с помощью инструментов Pip и Conda?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Как установить LangChain из исходного кода?</td>\n",
       "      <td>Как можно установить LangChain из исходного кода?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Что представляет собой пакет 'langchain-experimental' и как его установить?</td>\n",
       "      <td>Какой пакет называется 'langchain-experimental' и как его можно установить?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Как установить LangServe и для чего он используется?</td>\n",
       "      <td>Что такое LangServe и как его использовать?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Как установить LangChain CLI и в чем его предназначение?</td>\n",
       "      <td>Что такое LangChain CLI и как его использовать?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Что такое LangSmith SDK и как его установить?</td>\n",
       "      <td>Как можно установить LangSmith SDK?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Какие интеграции предлагает LangChain и как они способствуют созданию приложений?</td>\n",
       "      <td>Какие возможности для интеграции предоставляет LangChain и как они помогают в создании приложений?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Какие лучшие практики безопасности следует учитывать при работе с LangChain?</td>\n",
       "      <td>Какие меры безопасности необходимо соблюдать при работе с технологией LangChain?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Какие риски существуют при недостаточной защите приложений LangChain и как их предотвратить?</td>\n",
       "      <td>Какие опасности могут возникнуть при недостаточной защите приложений LangChain и как можно предотвратить эти риски?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Как сообщить о проблеме безопасности в LangChain?</td>\n",
       "      <td>Как можно уведомить о возникшей угрозе безопасности в цепочке блоков (LangChain)?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Какие решения предлагает LangChain для корпоративных клиентов с особыми требованиями безопасности?</td>\n",
       "      <td>Какие меры безопасности предлагает LangChain для корпоративных клиентов с особыми потребностями?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Каковы основные методы и их назначение в протоколе 'Runnable' LangChain?</td>\n",
       "      <td>Какие методы используются в протоколе 'Runnable' LangChain и для чего они предназначены?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Как работает метод 'stream' в LangChain и каков его пример использования?</td>\n",
       "      <td>Что представляет собой метод 'stream' в LangChain и как он используется на практике?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             questions  \\\n",
       "0                                                      Что такое LangChain и для чего он используется?   \n",
       "1                                            Какие основные части включает в себя фреймворк LangChain?   \n",
       "2                                             Какие ключевые преимущества предлагают пакеты LangChain?   \n",
       "3                                                                Что такое LCEL в контексте LangChain?   \n",
       "4                                                                Какие модули предоставляет LangChain?   \n",
       "5                                      Какие примеры использования LangChain приведены в документации?   \n",
       "6                                                     Какова роль LangChain в экосистеме инструментов?   \n",
       "7                                               Как установить LangChain с использованием Pip и Conda?   \n",
       "8                                                          Как установить LangChain из исходного кода?   \n",
       "9                          Что представляет собой пакет 'langchain-experimental' и как его установить?   \n",
       "10                                                Как установить LangServe и для чего он используется?   \n",
       "11                                            Как установить LangChain CLI и в чем его предназначение?   \n",
       "12                                                       Что такое LangSmith SDK и как его установить?   \n",
       "13                   Какие интеграции предлагает LangChain и как они способствуют созданию приложений?   \n",
       "14                        Какие лучшие практики безопасности следует учитывать при работе с LangChain?   \n",
       "15        Какие риски существуют при недостаточной защите приложений LangChain и как их предотвратить?   \n",
       "16                                                   Как сообщить о проблеме безопасности в LangChain?   \n",
       "17  Какие решения предлагает LangChain для корпоративных клиентов с особыми требованиями безопасности?   \n",
       "18                            Каковы основные методы и их назначение в протоколе 'Runnable' LangChain?   \n",
       "19                           Как работает метод 'stream' в LangChain и каков его пример использования?   \n",
       "\n",
       "                                                                                                    rephrased_questions  \n",
       "0                                                              Для чего предназначен LangChain и что это за технология?  \n",
       "1                                                                Какие компоненты входят в состав фреймворка LangChain?  \n",
       "2                                                           Какие основные преимущества предоставляют пакеты LangChain?  \n",
       "3                                                                             В контексте LangChain, что означает LCEL?  \n",
       "4                                                                Какие функциональные возможности предлагает LangChain?  \n",
       "5                                                       В документации приведены какие примеры использования LangChain?  \n",
       "6                                                                Какую роль играет LangChain в экосистеме инструментов?  \n",
       "7                                              Как можно установить пакет LangChain с помощью инструментов Pip и Conda?  \n",
       "8                                                                     Как можно установить LangChain из исходного кода?  \n",
       "9                                           Какой пакет называется 'langchain-experimental' и как его можно установить?  \n",
       "10                                                                          Что такое LangServe и как его использовать?  \n",
       "11                                                                      Что такое LangChain CLI и как его использовать?  \n",
       "12                                                                                  Как можно установить LangSmith SDK?  \n",
       "13                   Какие возможности для интеграции предоставляет LangChain и как они помогают в создании приложений?  \n",
       "14                                     Какие меры безопасности необходимо соблюдать при работе с технологией LangChain?  \n",
       "15  Какие опасности могут возникнуть при недостаточной защите приложений LangChain и как можно предотвратить эти риски?  \n",
       "16                                    Как можно уведомить о возникшей угрозе безопасности в цепочке блоков (LangChain)?  \n",
       "17                     Какие меры безопасности предлагает LangChain для корпоративных клиентов с особыми потребностями?  \n",
       "18                             Какие методы используются в протоколе 'Runnable' LangChain и для чего они предназначены?  \n",
       "19                                 Что представляет собой метод 'stream' в LangChain и как он используется на практике?  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(question_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d6rKIozMkHb",
    "outputId": "3f6ef8dd-3033-48a0-ea02-5514cf5073d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на переформулированных вопросах 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Точность на переформулированных вопросах {relevant_in_top_n / doc_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ofz5ZI60MkHb"
   },
   "source": [
    "# Как видим, на сабсемпле данных эмбеддинг одинакого хорошо работает как на точных вопросах, так и на перефразированных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVHgQf_uMkHb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
